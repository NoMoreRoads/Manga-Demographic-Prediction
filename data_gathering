#!/usr/bin/env python3

# Copyright 2024 Zach Lesher <lesher.zachary@protonmail.com>
# SPDX-License-Identifier: MIT

"""
This script queries the Anilist API and saves every manga listing that fits within set parameters.
The resulting JSON is then parsed into a pandas dataframe, with some transformations done 
beforehand where it makes sense. The resulting pandas dataframe is then exported as a csv file.
"""

from collections import defaultdict
import json
import time
import logging
import sys
import random
import requests
import pandas as pd

LOG_LEVEL = logging.DEBUG
log = logging.getLogger(__name__)
logging.basicConfig(stream=sys.stderr, encoding="utf-8", level=LOG_LEVEL)

# Here we define our query as a multi-line string
QUERY = """
query ($page: Int) {
  Page (page: $page, perPage: 50) {
    media (type: MANGA, popularity_greater: 200, isAdult: false) {
        id
            chapters
            volumes
        title{
            english
            romaji
        }
        status
        startDate {
          year
          month
          day
        }
        stats {
          scoreDistribution {
            score
            amount
          }
          statusDistribution {
            status
            amount
          }
        }
        favourites
        source
        genres
        countryOfOrigin
        tags{
            name
            rank
            isAdult
        }
        endDate{
          year
          month
          day
        }
      relations{
        edges{
          relationType
          node{
              type
          }
        }
      }
      characters{
        edges {
          role
          node{
            gender
          }
        }
      }
    }
  }
}
"""

# Defining URL for request
URL = "https://graphql.anilist.co"

# Defining empty list to store the entire set of the
# multiple requests we will make
manga_list = []

# Defining the page number to start on
page_num = 1

# Looping through the number of pages needed to grab all of the manga
# records neccesary
while True:
    # 1. Making and saving request
    response = requests.post(URL, json={"query": QUERY,
                                        "variables": {"page": page_num}},
                                        timeout=15)
    log.debug(response.headers)
    rs_status = response.status_code
    rs_data = json.loads(response.text)["data"]

    # 2. Checking if response has hit rate limit; if so wait & try again
    if rs_status == 429:
        log.debug("too many requests! waiting for a bit...")
        rs_retry_time = response.headers["Retry-After"]
        log.debug("should wait for %s seconds", rs_retry_time)
        time.sleep(int(rs_retry_time) + 1)
        continue

    # 3. Checking if response is an unexpected code; if so stopping script altogether
    if rs_status not in [200, 429]:
        sys.exit("got a weird response! Try running this script again.")

    log.debug("response_list.len: %s", len(manga_list))
    log.debug(rs_status)
    log.debug(response.headers)
    log.debug(rs_data is None)

    # 4. Checking if response got valid but blank response; ending loop if so
    if rs_status == 200 and len(rs_data["Page"]["media"]) == 0:
        break

    # 5. Appending relevant information to
    manga_list += rs_data["Page"]["media"]

    # 6. Waiting to avoid triggering timeout, if possible
    time.sleep(random.uniform(0.5, 1.5))

    # 7. Incremeting page number to query
    page_num += 1

# Creating empty list to be filled with dictionaries, each one representing a
# manga, to be later converted to a pandas dataframe
staging_list = []
entry = defaultdict(int)

# A series of loops to un-nest the json file in the format described above
for manga in manga_list:
    entry = defaultdict(int, {
        "id": manga["id"],
        "eng_title": manga["title"]["english"].rstrip,
        "rom_title": manga["title"]["romaji"].rstrip,
        "status": manga["status"],
        "chapters": manga["chapters"],
        "volumes": manga["volumes"],
        "start_year": manga["startDate"]["year"],
        "start_month": manga["startDate"]["month"],
        "start_day": manga["startDate"]["day"],
        "end_year": manga["endDate"]["year"],
        "end_month": manga["endDate"]["month"],
        "end_day": manga["endDate"]["day"],
        "favorites": manga["favourites"],
        "source": manga["source"],
        "country": manga["countryOfOrigin"]
    } )

    for score_bucket in manga["stats"]["scoreDistribution"]:
        entry[f"scored_{score_bucket['score']}_count"] \
            = score_bucket["amount"]

    for status in manga["stats"]["statusDistribution"]:
        entry[f"status_{status['status']}_count"] \
            = status["amount"]

    for genre in manga["genres"]:
        entry[genre] = 1

    for tag in manga["tags"]:
        if tag["isAdult"] is True:
            continue
        entry[tag["name"]] = tag["rank"]

    for relation in manga["relations"]["edges"]:
        entry["relation_" + relation["relationType"]] += 1
        entry["relationmedia_" + relation["node"]["type"]] += 1

    for character in manga["characters"]["edges"]:
        entry["total_" + character["role"].str.lower() + "_roles"] += 1
        entry[character["node"]["gender"] + "_" + character["role"].str.lower() + "_roles"] += 1

    staging_list.append(entry)

# Converting list of dictionaries into pandas dataframe
df_whole = pd.DataFrame(staging_list)

df_whole.to_csv("manga.csv", index=False)
