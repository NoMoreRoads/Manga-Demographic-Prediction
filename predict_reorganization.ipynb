{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Setup**\n",
    "\n",
    "Importing modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import imblearn\n",
    "import sklearn.inspection\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting Pandas options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 400)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_original = pd.read_csv('manga.csv', na_values = 'nan')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data Exploration Phase 1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_original.describe().transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data Wrangling**\n",
    "\n",
    "Handling missing values differently depending on the feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "updated_df_1 = df_original\n",
    "updated_df_1[\"chapters\"] = df_original[\"chapters\"].fillna(value=-1)\n",
    "updated_df_1[\"volumes\"] = updated_df_1[\"volumes\"].fillna(value=-1)\n",
    "\n",
    "\n",
    "numeric_columns = df_original.select_dtypes(include=['number']).columns\n",
    "\n",
    "updated_df_1 = df_original\n",
    "updated_df_1[numeric_columns] = updated_df_1[numeric_columns].fillna(value=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converting start and end dates into number of days since Jan 1, 1950"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "updated_df_1_5[\"start_date_days\"] = (updated_df_1[\"start_date\"]\n",
    "    - datetime.datetime(1950, 1, 1)).transform(lambda x: x.days)\n",
    "updated_df_1_5[\"end_date_days\"] = (updated_df_1[\"end_date\"]\n",
    "    - datetime.datetime(1950, 1, 1)).transform(lambda x: x.days)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replacing individual demographic tag columns with a single label column to be used as the target feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demographic_labels = [\"Shounen\",\"Shoujo\",\"Seinen\",\"Josei\"]\n",
    "demo_only_df = updated_df_1.loc[:,demographic_labels]\n",
    "\n",
    "# Finding instances with no clear demographic tag\n",
    "total_pct_per_row = demo_only_df.sum(axis=1).tolist()\n",
    "indices = [index for index, element in enumerate(total_pct_per_row) if element == 0]\n",
    "\n",
    "# Finding best fit for each row, aside from no-tag cases\n",
    "demo_column_1 = demo_only_df.idxmax(axis=1).tolist()\n",
    "demo_column_2 = demo_column_1\n",
    "\n",
    "# Replacing best fit demographic with \"Unknown\" in cases with no clear demographic tag\n",
    "for index in indices:\n",
    "    demo_column_2[index] = \"Unknown\"\n",
    "\n",
    "# Adding column\n",
    "updated_df_2 = updated_df_1\n",
    "updated_df_2[\"Demographic\"] = demo_column_2\n",
    "\n",
    "# Removing demographic tag columns\n",
    "updated_df_3 = updated_df_2.drop(demographic_labels, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recalculating status and score features; adding some additional calculated features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting current list of columns\n",
    "columns_list_v3 = updated_df_3.columns.tolist()\n",
    "\n",
    "# Creating list of status columns only\n",
    "status_regex = re.compile(\"status_\")\n",
    "status_raws_cols = list(filter(status_regex.match, columns_list_v3))\n",
    "\n",
    "# Summing status columns only\n",
    "popularity_list = updated_df_3[status_raws_cols].sum(axis=1).tolist()\n",
    "\n",
    "# Adding new column\n",
    "updated_df_4 = updated_df_3\n",
    "updated_df_4[\"Popularity\"] = popularity_list\n",
    "\n",
    "# Recalculating statuses to be a percentage of popularity\n",
    "for column in status_raws_cols:\n",
    "    updated_df_4 = updated_df_4.assign(**{column: updated_df_4[column]/updated_df_4[\"Popularity\"]})\n",
    "\n",
    "# Renaming status columns to reflect their new meaning (this also renames score columns, which will be updated later)\n",
    "updated_df_4.columns = updated_df_4.columns.str.replace(\"_count\", \"_pct\", regex=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting current list of columns\n",
    "columns_list_v4 = updated_df_4.columns.tolist()\n",
    "\n",
    "# Creating list of score columns only\n",
    "score_regex = re.compile(\"scored_\")\n",
    "score_raws_cols = list(filter(score_regex.match, columns_list_v4))\n",
    "\n",
    "# Summing score columns only\n",
    "score_list = updated_df_4[score_raws_cols].sum(axis=1).tolist()\n",
    "\n",
    "# Adding new column\n",
    "updated_df_5 = updated_df_4\n",
    "updated_df_5[\"Scored_Percentage\"] = score_list\n",
    "\n",
    "# Recalculating statuses to be a percentage of popularity\n",
    "for column in score_raws_cols:\n",
    "    updated_df_5 = updated_df_5.assign(**{column: updated_df_5[column]/updated_df_5[\"Scored_Percentage\"]})\n",
    "\n",
    "updated_df_5 = updated_df_5.assign(Scored_Percentage = updated_df_5[\"Scored_Percentage\"]/updated_df_5[\"Popularity\"])\n",
    "\n",
    "numeric_columns = updated_df_5.select_dtypes(include=['number']).columns\n",
    "updated_df_5[numeric_columns] = updated_df_5[numeric_columns].fillna(value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "updated_df_6 = updated_df_5.assign(favorites = updated_df_5[\"favorites\"]/updated_df_5[\"Popularity\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculating a run length feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "updated_df_7 = updated_df_6.assign(run_length = updated_df_6[\"end_date_days\"]-updated_df_6[\"start_date_days\"])\n",
    "updated_df_7[\"run_length\"] = updated_df_7[\"run_length\"].where(cond=updated_df_7[\"run_length\"]>-1, other=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "updated_df_8 = updated_df_7.drop([\"id\", \"eng_title\", \"rom_title\",\"start_date\",\"end_date\"], axis=1)\n",
    "updated_df_8 = pd.get_dummies(updated_df_8, dummy_na=True, columns=[\"status\",\"source\",\"country\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Balanced Random Forest Iterative Improvements**\n",
    "\n",
    "Splitting into training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_df = updated_df_8.query(\"Demographic != 'Unknown'\")\n",
    "training_x = training_df.drop(columns=[\"Demographic\"])\n",
    "training_y = training_df[[\"Demographic\"]]\n",
    "testing_df = updated_df_8.query(\"Demographic == 'Unknown'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing baseline classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfBaseline = imblearn.ensemble.BalancedRandomForestClassifier(n_estimators=500, replacement=True, bootstrap=False, random_state=1234, sampling_strategy=\"all\")\n",
    "cross_validator = sklearn.model_selection.KFold(n_splits=10, shuffle=True, random_state=1234)\n",
    "baseline_results = sklearn.model_selection.cross_val_score(rfBaseline, X=training_x, y=np.ravel(training_y), groups=None, scoring=\"recall_macro\",cv=cross_validator)\n",
    "baseline_results.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_preds = sklearn.model_selection.cross_val_predict(rfBaseline, X=training_x, y=np.ravel(training_y), cv=cross_validator)\n",
    "\n",
    "sklearn.metrics.ConfusionMatrixDisplay.from_predictions(y_true = np.ravel(training_y), y_pred= baseline_preds, labels=demographic_labels, normalize=\"true\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removing highly correlated features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = training_x.corr().stack().reset_index()\n",
    "temp_2 = temp.rename(columns={\"level_0\":\"first_var\", \"level_1\":\"second_var\", 0:\"correlation\"}, inplace=False)\n",
    "temp_2[\"correlation\"] = temp_2[\"correlation\"].abs()\n",
    "\n",
    "temp_3 = temp_2.query(\"first_var != second_var\").sort_values(\"correlation\", ascending=False)\n",
    "\n",
    "remvar = []\n",
    "temp_vals = training_x\n",
    "\n",
    "while temp_3.iloc[0,2] >= .8:\n",
    "    remvar.append(temp_3.iloc[0,0])\n",
    "    temp_vals = temp_vals.drop(remvar[-1], axis=1)\n",
    "    temp_3 = temp_vals.corr().stack().reset_index().rename(columns={\"level_0\":\"first_var\", \"level_1\":\"second_var\", 0:\"correlation\"}).query(\"first_var != second_var\")\n",
    "    temp_3[\"correlation\"] = temp_3[\"correlation\"].abs()\n",
    "    temp_3 = temp_3.sort_values(\"correlation\", ascending=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculating variable importance using permutation, removing features that improve prediction by less than 1/20th of a percent; checking that results have not resulted in a dramatic reduction in prediction score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfPermutation = imblearn.ensemble.BalancedRandomForestClassifier(n_estimators=100, replacement=True, bootstrap=False, random_state=1234, sampling_strategy=\"all\")\n",
    "rfPermutation.fit(temp_vals, np.ravel(training_y))\n",
    "\n",
    "permute_results = sklearn.inspection.permutation_importance(estimator=rfPermutation, X = temp_vals, y = training_y, scoring=\"recall_macro\", n_repeats=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perm_importance = pd.DataFrame()\n",
    "perm_importance[\"feature\"] = temp_vals.columns\n",
    "perm_importance[\"importance\"] = permute_results[\"importances_mean\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perm_features_tokeep = perm_importance.query(\"importance >= .00025\").feature\n",
    "\n",
    "refined_training = temp_vals[perm_features_tokeep]\n",
    "\n",
    "rfReduced = imblearn.ensemble.BalancedRandomForestClassifier(n_estimators=500, oob_score = True, replacement=False, bootstrap=True, random_state=1234, sampling_strategy=\"all\")\n",
    "\n",
    "reduced_cv_results = sklearn.model_selection.cross_val_score(rfReduced, X=refined_training, y=np.ravel(training_y), groups=None, scoring=\"recall_macro\",cv=cross_validator)\n",
    "reduced_cv_results.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "permutation_predictions = sklearn.model_selection.cross_val_predict(rfReduced, X=refined_training, y=np.ravel(training_y), cv=cross_validator)\n",
    "\n",
    "sklearn.metrics.ConfusionMatrixDisplay.from_predictions(y_true = np.ravel(training_y), y_pred= permutation_predictions, labels=demographic_labels, normalize=\"true\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performing randomized search to tune hyperparameters, testing scoring results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameter_dict = {\"criterion\": [\"gini\", \"entropy\"],\n",
    "                       \"max_depth\": [None, 3, 4, 5, 10, 15, 20, 25, 30, 40, 50, 60],\n",
    "                       \"min_samples_split\": [2, 3, 4, 5, 7, 10, 15],\n",
    "                       \"min_samples_leaf\": [1, 2, 4, 5],\n",
    "                       \"sampling_strategy\": [\"majority\", \"not minority\", \"not majority\", \"all\"],\n",
    "                       \"class_weight\": [None, \"balanced\", \"balanced_subsample\"]\n",
    "                       }\n",
    "\n",
    "RandomSearchrf = imblearn.ensemble.BalancedRandomForestClassifier(bootstrap=False, replacement=True, random_state=1234, n_estimators=500)\n",
    "\n",
    "rf_random = sklearn.model_selection.RandomizedSearchCV(estimator = RandomSearchrf, param_distributions = hyperparameter_dict, n_iter = 25, cv = 3, verbose=2, random_state=1234, scoring=\"recall_macro\")\n",
    "\n",
    "randsearch_output = rf_random.fit(refined_training, np.ravel(training_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "randsearch_output.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xvalidated_classifier = randsearch_output.best_estimator_\n",
    "\n",
    "xvalidated_classifier.get_params()[\"n_estimators\"] = 10000\n",
    "\n",
    "optimal_model_results = sklearn.model_selection.cross_val_score(xvalidated_classifier, X=refined_training, y=np.ravel(training_y), groups=None, scoring=\"recall_macro\",cv=cross_validator)\n",
    "optimal_model_results.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparam_tuned_predictions = sklearn.model_selection.cross_val_predict(xvalidated_classifier, X=refined_training, y=np.ravel(training_y), cv=cross_validator)\n",
    "\n",
    "sklearn.metrics.ConfusionMatrixDisplay.from_predictions(y_true = np.ravel(training_y), y_pred= hyperparam_tuned_predictions, labels=demographic_labels, normalize=\"true\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking reduced"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Regular Random Forest Iterative Approach**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modified df baseline normal\n",
    "# permute, check again\n",
    "# hyperparameter tuning\n",
    "# cross validate best hyperparameter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking baseline results of model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BaselineNonbalancedrf = sklearn.ensemble.RandomForestClassifier(n_estimators=500, random_state=1234)\n",
    "\n",
    "baseline_results_unbalanced = sklearn.model_selection.cross_val_score(BaselineNonbalancedrf, X=training_x, y=np.ravel(training_y), groups=None, scoring=\"recall_macro\",cv=cross_validator)\n",
    "baseline_results_unbalanced.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_nonbalanced_preds = sklearn.model_selection.cross_val_predict(BaselineNonbalancedrf, X=training_x, y=np.ravel(training_y), cv=cross_validator)\n",
    "\n",
    "sklearn.metrics.ConfusionMatrixDisplay.from_predictions(y_true = np.ravel(training_y), y_pred= baseline_nonbalanced_preds, labels=demographic_labels, normalize=\"true\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removing features using permutation (this time using a wider threshold for retaining features due to relatively low average feature importance); testing new score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfPermutation_unbalanced = sklearn.ensemble.RandomForestClassifier(n_estimators=100, random_state=1234)\n",
    "rfPermutation_unbalanced.fit(temp_vals, np.ravel(training_y))\n",
    "\n",
    "permute_results_imbalanced = sklearn.inspection.permutation_importance(estimator=rfPermutation_unbalanced, X = temp_vals, y = training_y, scoring=\"recall_macro\", n_repeats=3)\n",
    "\n",
    "perm_importance_imbalanced = pd.DataFrame()\n",
    "perm_importance_imbalanced[\"feature\"] = temp_vals.columns\n",
    "perm_importance_imbalanced[\"importance\"] = permute_results_imbalanced[\"importances_mean\"]\n",
    "\n",
    "\n",
    "perm_features_tokeep_imbalanced = perm_importance_imbalanced.query(\"importance >= .00025\").feature\n",
    "\n",
    "refined_training_imbalanced = temp_vals[perm_features_tokeep_imbalanced]\n",
    "\n",
    "rfReduced_imbalanced = sklearn.ensemble.RandomForestClassifier(n_estimators=500, random_state=1234)\n",
    "\n",
    "reduced_cv_results = sklearn.model_selection.cross_val_score(rfReduced_imbalanced, X=refined_training_imbalanced, y=np.ravel(training_y), groups=None, scoring=\"recall_macro\",cv=cross_validator)\n",
    "reduced_cv_results.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "permutation_imbalanced_predictions = sklearn.model_selection.cross_val_predict(rfReduced_imbalanced, X=refined_training_imbalanced, y=np.ravel(training_y), cv=cross_validator)\n",
    "\n",
    "sklearn.metrics.ConfusionMatrixDisplay.from_predictions(y_true = np.ravel(training_y), y_pred= permutation_imbalanced_predictions, labels=demographic_labels, normalize=\"true\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performing randomized search to tune hyperparameters, testing scoring results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameter_dict_imbalanced = {\"criterion\": [\"gini\", \"entropy\"],\n",
    "                       \"max_depth\": [None, 3, 4, 5, 10, 15, 20, 25, 30, 40, 50, 60],\n",
    "                       \"min_samples_split\": [2, 3, 4, 5, 7, 10, 15],\n",
    "                       \"min_samples_leaf\": [1, 2, 4, 5],\n",
    "                       \"class_weight\": [None, \"balanced\", \"balanced_subsample\"]\n",
    "                       }\n",
    "\n",
    "\n",
    "RandomSearchrf_imbalanced = sklearn.ensemble.RandomForestClassifier(random_state=1234, n_estimators=500)\n",
    "\n",
    "rf_random_imbalanced = sklearn.model_selection.RandomizedSearchCV(estimator = RandomSearchrf_imbalanced, param_distributions = hyperparameter_dict_imbalanced, n_iter = 25, cv = 3, verbose=2, random_state=1234, scoring=\"recall_macro\")\n",
    "\n",
    "randsearch_output_imbalanced = rf_random.fit(refined_training_imbalanced, np.ravel(training_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xvalidated_classifier_imbalanced = randsearch_output_imbalanced.best_estimator_\n",
    "\n",
    "xvalidated_classifier_imbalanced.get_params()[\"n_estimators\"] = 10000\n",
    "\n",
    "optimal_model_results_imbalanced = sklearn.model_selection.cross_val_score(xvalidated_classifier_imbalanced, X=refined_training_imbalanced, y=np.ravel(training_y), groups=None, scoring=\"recall_macro\",cv=cross_validator)\n",
    "optimal_model_results_imbalanced.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imbalanced_hyperparam_tuned_predictions = sklearn.model_selection.cross_val_predict(xvalidated_classifier_imbalanced, X=refined_training_imbalanced, y=np.ravel(training_y), cv=cross_validator)\n",
    "\n",
    "sklearn.metrics.ConfusionMatrixDisplay.from_predictions(y_true = np.ravel(training_y), y_pred= imbalanced_hyperparam_tuned_predictions, labels=demographic_labels, normalize=\"true\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
